{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bace05de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel\n",
    "import google.genai as genai\n",
    "from google.genai import types\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.language_models import BaseChatModel\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough,RunnableLambda,RunnableMap\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.prompt_values import StringPromptValue\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04f9a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157331b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader('./assets/constitution.pdf')\n",
    "pdf = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a9d743",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "vector_store = FAISS.from_documents(embedding=model,documents=pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6031f90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyWords(BaseModel):\n",
    "    keywords: list[str]\n",
    "    \n",
    "client = genai.Client(api_key=api_key)\n",
    "    \n",
    "sys = types.GenerateContentConfig(\n",
    "    temperature=0.2,\n",
    "    response_schema=KeyWords,\n",
    "    response_mime_type=\"application/json\",\n",
    "    system_instruction=\"On the basis of the user's question, return a list of at least 5 relevant keywords (terms, article numbers, or important phrases) which can be used for searching within the Indian Constitution.\"\n",
    ")\n",
    "def retriever(query,api_key=api_key):\n",
    "    response = client.models.generate_content(\n",
    "        contents = query[\"question\"],\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        config= sys\n",
    "    ).parsed\n",
    "    if(len(response.keywords) == 0):\n",
    "        return \"There is no relevent context in the document, answer generically if possible\"\n",
    "    search = \" \".join(response.keywords)\n",
    "    content = vector_store.similarity_search(search,5)\n",
    "    context = \"\"\"\"\"\"\n",
    "    for page in content:\n",
    "        context += page.page_content + \"\\n\"\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825cce93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class customModel(BaseChatModel):\n",
    "    def __init__(self,api_key:str):\n",
    "        client = genai.Client(api_key=api_key)\n",
    "        object.__setattr__(self,\"client\",client)\n",
    "        system = types.GenerateContentConfig(\n",
    "            temperature=0.8,\n",
    "            system_instruction=\"\"\"You are a chatbot that will answer the questions Related to Indian Constitution.\n",
    "            You will be given context, which are a few pages of indian constitution and the question to answer the answer of questions related to Indian constitution.\n",
    "            You can answer generic question by urself and also you can use your info in answering questions\n",
    "            \"\"\"\n",
    "        )\n",
    "        object.__setattr__(self,\"system\",system)\n",
    "        \n",
    "    def _generate(self, messages:str)->str:\n",
    "        response = self.client.models.generate_content(\n",
    "            contents=messages,\n",
    "            model=\"gemini-2.0-flash\",\n",
    "            config=self.system\n",
    "        )\n",
    "        return response.text\n",
    "    \n",
    "    def invoke(self, input:StringPromptValue, config = None)->AIMessage:\n",
    "        question = input.to_string()\n",
    "        response = self._generate(question)\n",
    "        return AIMessage(content=response)\n",
    "         \n",
    "    @property\n",
    "    def _llm_type(self):\n",
    "        return \"custom_gemini\"\n",
    "    \n",
    "    @property\n",
    "    def callback(self):\n",
    "        return []\n",
    "    \n",
    "    @property\n",
    "    def streaming(self):\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b0b4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the following questions on the basis of given context.\n",
    "question : {question}\n",
    "context : {context}                                                   \n",
    "\"\"\")\n",
    "\n",
    "llm = customModel(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c552de",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (RunnableMap({\"context\":RunnableLambda(retriever),\"question\":RunnablePassthrough()})\n",
    "| prompt_template\n",
    "| llm\n",
    "| StrOutputParser()         \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1148261f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(messages,history):\n",
    "    return chain.invoke({\"question\":messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbe7595",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(chat).launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
